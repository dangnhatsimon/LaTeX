% FortySecondsCV LaTeX template
% Copyright © 2019-2020 René Wirnata <rene.wirnata@pandascience.net>
% Licensed under the 3-Clause BSD License. See LICENSE file for details.
%
% Please visit https://github.com/PandaScience/FortySecondsCV for the most
% recent version! For bugs or feature requests, please open a new issue on
% github.
%
% Contributors
% ------------
% * ifokkema
% * Bertbk
% * Hespe
%
% Attributions
% ------------
% * fortysecondscv is based on the twentysecondcv class by Carmine Spagnuolo
%   (cspagnuolo@unisa.it), released under the MIT license and available under
%   https://github.com/spagnuolocarmine/TwentySecondsCurriculumVitae-LaTex
% * further attributions are indicated immediately before corresponding code


%-------------------------------------------------------------------------------
%                             ADDITIONAL PACKAGES
%-------------------------------------------------------------------------------
\documentclass[
	a4paper,
	% showframes,
	% vline=2.2em,
	% maincolor=cvgreen,
	% sidecolor=gray!50,
	% sectioncolor=red,
	% subsectioncolor=orange,
	% itemtextcolor=black!80,
	% sidebarwidth=0.4\paperwidth,
	% topbottommargin=0.03\paperheight,
	% leftrightmargin=20pt,
	% profilepicsize=4.5cm,
	% profilepicborderwidth=3.5pt,
	% profilepicstyle=profilecircle,
	% profilepiczoom=1.0,
	% profilepicxshift=0mm,
	% profilepicyshift=0mm,
	% profilepicrounding=1.0cm,
]{fortysecondscv}

% improve word spacing and hyphenation
\usepackage{microtype}
\usepackage{ragged2e}

% uncomment in case you don't want any hyphenation
% \usepackage[none]{hyphenat}

% take care of proper font encoding
\ifxetexorluatex
	\usepackage{fontspec}
	\defaultfontfeatures{Ligatures=TeX}
%	\newfontfamily\headingfont[Path = fonts/]{segoeuib.ttf} % local font
\else
	\usepackage[utf8]{inputenc}
	\usepackage[T1]{fontenc}
%	\usepackage[sfdefault]{noto} % use noto google font
\fi

% enable mathematical syntax for some symbols like \varnothing
\usepackage{amssymb}

% bubble diagram configuration
\usepackage{smartdiagram}
\smartdiagramset{
	% default font size is \large, so adjust to harmonize with sidebar layout
	bubble center node font = \footnotesize,
	bubble node font = \footnotesize,
	% default: 4cm/2.5cm; make minimum diameter relative to sidebar size
	bubble center node size = 0.4\sidebartextwidth,
	bubble node size = 0.25\sidebartextwidth,
	distance center/other bubbles = 1.5em,
	% set center bubble color
	bubble center node color = maincolor!70,
	% define the list of colors usable in the diagram
	set color list = {maincolor!10, maincolor!40,
	maincolor!20, maincolor!60, maincolor!35},
	% sets the opacity at which the bubbles are shown
	bubble fill opacity = 0.8,
}


%-------------------------------------------------------------------------------
%                            PERSONAL INFORMATION
%-------------------------------------------------------------------------------
%% mandatory information
% your name
\cvname{DANG NHAT}
% job title/career
\cvjobtitle{DATA ENGINEER}

%% optional information
% profile picture
\cvprofilepic{anhCV.png}

% NOTE: ordering in sidebar will mimic the following order
% date of birth
\cvbirthday{12/04/1995}
% short address/location, use \newline if more than 1 line is required
\cvaddress{Go Vap District, HCMC}
% phone number
\cvphone{+84 0354883673}
% personal website
%\cvsite{https://pandascience.net}
% email address
\cvmail{dangnhatsimon@gmail.com}
% pgp key
%\cvkey{4096R/FF00FF00}{0xAABBCCDDFF00FF00}
% any other custom entry
%\cvcustomdata{\faFlag}{Chinese}

%-------------------------------------------------------------------------------
%                              SIDEBAR 1st PAGE
%-------------------------------------------------------------------------------
% add more profile sections to sidebar on first page
\addtofrontsidebar{
	% include gosquare national flags from https://github.com/gosquared/flags;
	% naming according to ISO 3166-1 alpha-2 country codes
	\graphicspath{{pics/flags/}}

	% social network accounts incl. proper hyperlinks
	\profilesection{Profile}
		\begin{icontable}{2.5em}{1em}
			\social{\faLinkedin}
				{https://www.linkedin.com/in/dangnhatsimon/}
				{LinkedIn}
			\social{\faGithub}
				{https://github.com/dangnhatsimon}
				{Github}
                \social{\faLeetCode}
				{https://leetcode.com/u/dangnhatsimon/}
				{LeetCode}
		\end{icontable}

	
	% \profilesection{Hard Skills}
	% 	\skill{\faBalanceScale}{Sleeping almost all day}
	% 	\skill{\faSitemap}{Eating a lot of bamboo sprouts}
	% 	\skill{\faGraduationCap}{Relaxing rest of the day}


    \profilesection{Education}
    \textbf{Obninsk Institute for Nuclear Power Engineering}\\
    {B.Sc in Nuclear Power Engineering and Thermal Physics. (2014-2019)\\
    GPA: 4.6/5.0}\\
    \textbf{MongoDB University}\\{\href{https://learn.mongodb.com/c/cfFB2N4oSW-0JU3v4mSgCQ}{MongoDB Python Developer. (2024)}}\\
    \textbf{IBM Skills Network}\\{\href{https://www.coursera.org/account/accomplishments/specialization/certificate/KBYR4MSPABQ5}{Data Engineering. (2022)}}\\
    \textbf{DataCamp}\\
    {\href{https://www.datacamp.com/completed/statement-of-accomplishment/track/f5a2f36cc340f546df4cf0b90eb172a8eb919a97}{Professional Data Engineer. (2024)}}\\
    {\href{https://www.datacamp.com/completed/statement-of-accomplishment/track/41b2fb00f337e93c50fcae8674ee68ce97224c02}{Big Data with PySpark. (2024)}}\\
    \textbf{Google Career}\\{\href{https://coursera.org/share/96a1a8db90424f56a3ada058c9f1ab7c}{IT Automation with Python. (2021)}}\\{\href{https://coursera.org/share/81539bd07606f96b7ae9b995b37e0fa8}{Data Analytics. (2021)}}\\
}
%-------------------------------------------------------------------------------
%                              SIDEBAR 2nd PAGE
%-------------------------------------------------------------------------------
\addtobacksidebar{
	% \profilesection{About Me}
	% \aboutme{
	% 	I am a results-driven Data Engineer with a passion for creating efficient data pipelines and optimizing data workflows. My expertise lies in designing and implementing robust data warehouses, modeling data structures for optimal performance, and integrating diverse data sources. With hands-on experience in data transformation and real-time processing, I am adept at turning raw data into actionable insights.
	% }
    \profilesection{Certificate}
    {\href{https://courses.cognitiveclass.ai/certificates/8c9b8d31294e425fb4a9ee7adc634829}{IBM -  Big Data 101.}}\\
    {\href{https://courses.cognitiveclass.ai/certificates/98e026c1d2ad48fcb99ef692d846b255}{IBM - Hadoop 101.}}\\
    {\href{https://www.datacamp.com/completed/statement-of-accomplishment/course/41e9a0f6325b81008c8d47fe1b8021c9ebb39f21}{DataCamp - Building Data Pipelines.}}\\
    {\href{https://www.freecodecamp.org/certification/dangnhatsimon/data-analysis-with-python-v7}{freeCodeCamp - Data Analysis with Python.}}\\
    {\href{https://www.hackerrank.com/certificates/eab550ff20e4}{Hackerrank - Problem Solving Basic.}}\\
    {\href{https://www.hackerrank.com/certificates/2d7e4cc8252e}{Hackerrank - Python Basic.}}\\
    {\href{https://www.hackerrank.com/certificates/6687993f90b4}{Hackerrank - SQL Advanced.}}\\
    {\href{https://www.sololearn.com/certificates/CC-GAXYBUN8}{Sololearn - Python Developer.}}\\
    {\href{https://www.sololearn.com/certificates/CC-TNLZFHT2}{Sololearn - Python Intermediate.}}\\
    {\href{https://www.sololearn.com/certificates/CC-Q4PRY1LC}{Sololearn - SQL Intermediate.}}

    \profilesection{Languages}
        \begin{sidebarminipage}
            \chartlabel{Vietnamese}\chartlabel{English}\chartlabel{Russian}\\
            \chartlabel{Chinese}
        \end{sidebarminipage}

%	\profilesection{Diagrams}
%	\begin{sidebarminipage}
%	\chartlabel{with}
%		\chartlabel{proper}
%		\chartlabel{overflow}
%		\chartlabel{protection}
%		\chartlabel{for}
%		\chartlabel{labels}
%	\end{sidebarminipage}

%	\begin{figure}\centering
%		\smartdiagram[bubble diagram]{
%			\textcolor{white}{\textbf{Being a}} \\
%			\textcolor{white}{\textbf{Panda}}, % center bubble
%			\textcolor{black!90}{Eating},
%			\textcolor{black!90}{Sleeping},
%			\textcolor{black!90}{Rolling},
%			\textcolor{black!90}{Playing},
%			\textcolor{black!90}{Chilling}
%		}
%	\end{figure}

%	\chartlabel{Wheel Chart}
%
%	\wheelchart{3.7em}{2em}{%
%	20/3em/maincolor!50/Chill,
%	15/3em/maincolor!15/Play,
%	20/3em/maincolor!20/Eat
%	}

	% \profilesection{Barskills}
	% \barskill{\faSkyatlas}{Wearing asian rice hats}{60}
	% \barskill{\faImage}{Playing Chess}{30}
	% \barskill{\faMusic}{Playing the bamboo flute}{50}

%	\profilesection{Memberships}
%	\begin{memberships}
%		\membership[4em]{pics/logo.png}{PandaScience.net}
%		\membership[4em]{pics/logo.png}{Some longer text spanning over more than
%			only one line}
%	\end{memberships}
}


%-------------------------------------------------------------------------------
%                         TABLE ENTRIES RIGHT COLUMN
%-------------------------------------------------------------------------------
\begin{document}

\makefrontsidebar
\cvsection{Working Experience}
\begin{cvtable}[3]
     \cvitem{May 2024 -- Present}{Data Engineer Specialist}{\\\href{https://www.greenfeed.com.vn/en/}{GREENFEED Vietnam Corporation - Fulltime}}{
    - GREENFEED is a fully integrated clean food chain FEED – FARM – FOOD with the mission to build quality and trusted brands that relentlessly innovate and create sustainable values for customers and society.\\
    - ELT \& Data Integration: designed, built, and tested end-to-end ELT workflows using Docker, integrating data from diverse sources such as SAP, Solomon, MISA, Porcitec, and FileSystem.\\
    - Streaming Data Pipelines: developed real-time data pipelines using Apache Kafka and Spark Streaming, enabling low-latency processing of streaming data from IoT devices and external sources.\\
    - Batch Data Processing: designed and executed scheduled data transformation workflows using PySpark on Apache Airflow \& Spark, efficiently processing large-scale batch data.\\
    - Big Data Platform: built from scratch a Docker-based big data platform using Dockerfile and Docker Compose, ensuring scalable and efficient deployment of Apache Spark, Kafka, and Airflow.\\
    - Data Pipelines \& Orchestration: developed and monitored robust batch and streaming pipelines using Airbyte, Airflow, Apache Beam (Dataflow), Spark Streaming, and Structured Streaming.\\
    - Metadata Management \& Data Lineage: implemented OpenLineage to track and manage data lineage, dependencies, and metadata across Airflow and Spark pipelines.\\
    - Data Migration: managed migration and synchronization of data from internal systems to AWS services such as S3 and Redshift.\\
    - Data Lakehouse: designed, built from scratch, and validated an AWS-based Lakehouse architecture for domains including Farm, Food, Social Media, Supply Chain, and Financial \& Accounting.\\
    - Data Transformation: leveraged DBT, Python, and Java to deliver clean, structured datasets for analytics and business intelligence.\\
    - Social Media Data Integration: built and managed data pipelines from social media platforms and APIs to the Lakehouse, enabling deeper insights from external data sources.\\
    - Documentation \& Collaboration: maintained through documentation and collaborated closely with stakeholders to ensure timely and aligned data solutions across FEED, FARM, and FOOD.\\
    - Skills: Python, Java, AWS, GCP, Spark, Beam, Kafka, Data Architecture, Docker, Kubernetes, GitLab, Integrated Businesses in Closed Loop.}
\end{cvtable}



%\cvsubsection{Study}
%\begin{cvtable}[1.5]
%	\cvitem{2006 -- 2008}{Master Studies Panda Science}{Panda Academy}
%		{Focus: Advanced rice hat studies and nouveau rain-reflecting cover
%		materials.}
%	\cvitem{}{Master Theses ($\varnothing\, 1,0$)}{Asian Rice Hat Institute}
%		{Impact of solar radiation onto rice hat cover materials with special
%		attention to water resistance.}
%	\cvitem{2003 -- 2006}{Bachelor Studies PandaScience}{Panda Academy}
%		{Focus: Bamboo morphology and its usage in different craftmanships.}
%	\cvitem{}{Bachelor Theses ($\varnothing\, 1,0$)}{Bamboo Institute}
%		{The bambo flute: An underestimated instrument in orchestras?}
%\end{cvtable}

%\cvsection{Publications}
%\begin{cvtable}
%	\cvpubitem{Cooking: 100 recipes for lazy Pandas}{Me and My Panda Friends}
%		{Panda's Culinary World}{2010}
%	\cvpubitem{Pandastasia}{Still Me}{Bamboo Books Assoc.}{2005}
%\end{cvtable}


%\cvsection{Awards}
%\begin{cvtable}
%	\cvitem{2010 -- now}{Panda of the Year}{Panda World Forum}{}
%	\cvitem{2005 -- now}{Face of World Wide Fund for Nature}{WWF}{}
%	\cvitem{2000}{Winner of Bamboo Sprouts Eating Contest}{Bamboo Society}{}
%\end{cvtable}


%\cvsection{Extra-Curricular Activities}
%\begin{cvtable}
%	\cvitemshort{Relaxing}{Master the fine art of relaxing everywhere}
%	\cvitemshort{Music}{Playing the bamboo flute in the 1st Panda Orchestra}
%	\cvitemshort{Education}{Teaching young pandas to be more panda-like}
%\end{cvtable}


\newpage
\makebacksidebar

\cvsection{}
\begin{cvtable}[3]
    \cvitem{Oct 2022 -- May 2024}{Data Engineer}{\\\href{https://pecc2.com/}{PECC2 - Fulltime}
    \\\href{https://definer.jp/}{Definer - Remote Part-time}}{
    - Definer specializes in building DevOps, automating cloud IT infrastructure, and developing analytical platforms for big data. PECC2 is a leading consultancy in the electricity energy industry, delivering power generation, transmission, and distribution solutions while leveraging data for efficiency and innovation.\\
    - Solution Design \& DevOps: architected and implemented comprehensive solutions with a focus on automating cloud IT infrastructure and workflows.\\
    - AWS \& CI/CD: developed task definitions and configuration files (CircleCI, Docker Compose, Dockerfile) to automate build, test, and deployment processes on AWS.\\
    - Containerization \& Orchestration: built Docker-based environments for scalable deployment of applications and data processing workflows.\\
    - Data Ingestion \& Processing: managed ingestion pipelines processing 1GB/day from power plant monitoring systems, ensuring data availability for Data Scientist and ML teams.\\
    - ETL \& Data Warehousing: designed and deployed data warehouses, built ETL pipelines, and developed interactive reports to enhance customer insights.\\
    - Data Migration \& Cloud Storage: automated data synchronization between internal servers and cloud platforms like AWS (S3, Redshift) and Google BigQuery.\\
    - Web Scraping \& API Development: extracted and processed data from dynamic JavaScript websites with pagination, utilizing APIs for automation and real-time insights.\\
    - Database Management: designed and optimized relational databases with advanced SQL techniques (views, transactions, stored procedures, joins), ensuring high performance and reliability.\\
    - Scripting \& Workflow Automation: developed Linux shell scripts, Python scripts, and cron jobs to automate catalog updates, supplier data processing, and document generation.\\
    - NoSQL Databases: designed and optimized large-scale NoSQL databases using MongoDB and Cassandra to handle high-throughput workloads and unstructured data efficiently.\\
    - Custom Tools \& Monitoring: created internal tools such as a Telegram bot for real-time data retrieval, keyword search GUIs, and system health monitoring scripts.\\
    - Skills: Data Engineering, ETL \& Data Pipelines, RDBMS, NoSQL and Big Data, Spark, Kafka, Beam, Python, SQL, Scripting, Docker, Git, Cloud.}    
\end{cvtable}

\cvsection{Skills}
\begin{cvtable}
    \cvitem{Domain}{Electricity, Agriculture, F\&B, Inventory.}{}{}
    \cvitem{Foundation}{Data Structures \& Algorithms, Probability \& Statistics.}{}{}
    \cvitem{Programming}{Python, Java, dbt, R, LaTeX.}{}{}
    \cvitem{Framework}{Flask, Django, Spring, Data Engineering.}{}{}
    \cvitem{Scripting}{Bash, Shell on Linux, Git.}{}{}
    \cvitem{Database}{SQL(MySQL, PostgreSQL, MSSQL), NoSQL(MongoDB, Cassandra), SAP.}{}{}
    \cvitem{Big Data}{Spark, Kafka, Beam, Hadoop.}{}{}
    \cvitem{Cloud}{AWS, GCP, IBM, Azure.}{}{}
    \cvitem{DevOps}{Docker, Kubernetes.}{}{}
    \cvitem{Visualization}{Tableau, Power BI.}{}{}
    \cvitem{Soft Skills}{Detail-oriented, Structured \& Analytical Thinking, Problem Solving, Teamwork, Diligent, Energentic, Resilient.}{}{}
   % \chartlabel{Detail-oriented}
   % \chartlabel{Structured thinking}
   % \chartlabel{Analytical thinking}
   % \chartlabel{Hard working}
   % \\
   % \chartlabel{Teamwork}
   % \chartlabel{Data Storytelling}
\end{cvtable}

% \newgeometry{
% 	top=\topbottommargin,
% 	bottom=\topbottommargin,
% 	right=\leftrightmargin,
% 	left=\leftrightmargin
% }

%\cvsection{section}
%\cvsubsection{Subsection}
%\begin{cvtable}
%	\cvitem{<dates>}{<cv-item title>}{<location>}{<optional: description>}
%\end{cvtable}

%\cvsection{cvitem}
%\cvsubsection{Multi-line with longer description}
%\begin{cvtable}
%	\cvitem{date}{Description}{location}{Some longer and more detailed
%		description, that takes two lines of space instead of only one.}
%	\cvitem{date}{Description}{location}{Some longer and more detailed
%		description, that takes two lines of space instead of only one.}
%	\cvitem{date}{Description}{location}{Some longer and more detailed
%		description, that takes two lines of space instead of only one.}
%\end{cvtable}

%\cvsubsection{One-line without description}
%\begin{cvtable}
%	\cvitem{Award}{One-line description}{Sponsor}{}
%	\cvitem{Award}{One-line description}{Sponsor}{}
%	\cvitem{Award}{One-line description}{Sponsor}{}
%\end{cvtable}

%\cvsection{cvitemshort}
%\cvsubsection{One-line}
%\begin{cvtable}
%	\cvitemshort{Key}{Some further description}
%	\cvitemshort{Key}{Some further description}
%	\cvitemshort{Key}{Some further description}
%\end{cvtable}

%\cvsubsection{Multi-line with longer description}
%\begin{cvtable}
%	\cvitemshort{Key}{Some further description. Can fill even more than
%		only one single line while still keeping the correct indendation level.}
%	\cvitemshort{Key}{Some further description. Can fill even more than
%		only one single line while still keeping the correct indendation level.}
%	\cvitemshort{Key}{Some further description. Can fill even more than
%		only one single line while still keeping the correct indendation level.}
%\end{cvtable}

%\cvsection{cvpubitem}
%\begin{cvtable}
%	\cvpubitem{Publication title}{Authors}{Journal}{Year}
%	\cvpubitem{Publication title}{Authors}{Journal}{Year}
%	\cvpubitem{Publication title that is spanning over multiple lines and still
%		does not look too bad}{Authors}{Journal}{Year}
%\end{cvtable}

% \cvsection{References}
% \begin{cvtable}
% 	\cvpubitem{Huynh The Minh, Data Engineer}{Parcel Perform}{htminh2307@gmail.com}{Ref. 1}
% 	\cvpubitem{Nguyen Nhat Nam, Data Scientist}{CEL}{nathan.nguyennhat@gmail.com}{Ref. 2}
% \end{cvtable}
% \cvsignature

\end{document}
